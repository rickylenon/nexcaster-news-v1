{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "id": "kmszWLtWHcU4",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Wav2Lip Inference Test - Google Colab\n",
        "\n",
        "This notebook sets up and runs Wav2Lip inference with chunked processing for optimal quality.\n",
        "\n",
        "## Command to test:\n",
        "```bash\n",
        "python wav2lip_test/Wav2Lip/inference_chunked.py \\\n",
        "  --checkpoint_path checkpoints/wav2lip.pth \\\n",
        "  --face test_video_newscaster.mp4 \\\n",
        "  --audio generated/audio/headline_opening_1.mp3 \\\n",
        "  --wav2lip_batch_size 4 \\\n",
        "  --resize_factor 2 \\\n",
        "  --chunk_size 25\n",
        "```\n",
        "\n",
        "**Note**: This notebook uses the working Hugging Face checkpoint download link instead of the broken Google Drive link.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting colabcode\n",
            "  Using cached colabcode-0.3.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting pyngrok>=5.0.0 (from colabcode)\n",
            "  Using cached pyngrok-7.3.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting nest-asyncio==1.4.3 (from colabcode)\n",
            "  Using cached nest_asyncio-1.4.3-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting uvicorn==0.13.1 (from colabcode)\n",
            "  Using cached uvicorn-0.13.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting jupyterlab==3.0.7 (from colabcode)\n",
            "  Downloading jupyterlab-3.0.7-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: ipython in ./venv_wav2lip/lib/python3.11/site-packages (from jupyterlab==3.0.7->colabcode) (9.4.0)\n",
            "Requirement already satisfied: packaging in ./venv_wav2lip/lib/python3.11/site-packages (from jupyterlab==3.0.7->colabcode) (25.0)\n",
            "Requirement already satisfied: tornado>=6.1.0 in ./venv_wav2lip/lib/python3.11/site-packages (from jupyterlab==3.0.7->colabcode) (6.5.1)\n",
            "Requirement already satisfied: jupyter-core in ./venv_wav2lip/lib/python3.11/site-packages (from jupyterlab==3.0.7->colabcode) (5.8.1)\n",
            "Collecting jupyterlab-server~=2.0 (from jupyterlab==3.0.7->colabcode)\n",
            "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting jupyter-server~=1.2 (from jupyterlab==3.0.7->colabcode)\n",
            "  Downloading jupyter_server-1.24.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting nbclassic~=0.2 (from jupyterlab==3.0.7->colabcode)\n",
            "  Downloading nbclassic-0.5.6-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: jinja2>=2.10 in ./venv_wav2lip/lib/python3.11/site-packages (from jupyterlab==3.0.7->colabcode) (3.1.6)\n",
            "Collecting click==7.* (from uvicorn==0.13.1->colabcode)\n",
            "  Downloading click-7.1.2-py2.py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting h11>=0.8 (from uvicorn==0.13.1->colabcode)\n",
            "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting PyYAML>=5.1 (from pyngrok>=5.0.0->colabcode)\n",
            "  Using cached PyYAML-6.0.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./venv_wav2lip/lib/python3.11/site-packages (from jinja2>=2.10->jupyterlab==3.0.7->colabcode) (3.0.2)\n",
            "Collecting anyio<4,>=3.1.0 (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode)\n",
            "  Downloading anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting argon2-cffi (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode)\n",
            "  Downloading argon2_cffi-25.1.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in ./venv_wav2lip/lib/python3.11/site-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (8.6.3)\n",
            "Collecting nbconvert>=6.4.4 (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode)\n",
            "  Downloading nbconvert-7.16.6-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting nbformat>=5.2.0 (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode)\n",
            "  Downloading nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting prometheus-client (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode)\n",
            "  Downloading prometheus_client-0.22.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pyzmq>=17 in ./venv_wav2lip/lib/python3.11/site-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (27.0.0)\n",
            "Collecting Send2Trash (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode)\n",
            "  Downloading Send2Trash-1.8.3-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting terminado>=0.8.3 (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode)\n",
            "  Downloading terminado-0.18.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: traitlets>=5.1 in ./venv_wav2lip/lib/python3.11/site-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (5.14.3)\n",
            "Collecting websocket-client (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode)\n",
            "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: platformdirs>=2.5 in ./venv_wav2lip/lib/python3.11/site-packages (from jupyter-core->jupyterlab==3.0.7->colabcode) (4.3.8)\n",
            "Collecting babel>=2.10 (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode)\n",
            "  Using cached babel-2.17.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode)\n",
            "  Downloading json5-0.12.0-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting jsonschema>=4.18.0 (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode)\n",
            "  Downloading jsonschema-4.25.0-py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: requests>=2.31 in ./venv_wav2lip/lib/python3.11/site-packages (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2.32.4)\n",
            "Collecting ipython-genutils (from nbclassic~=0.2->jupyterlab==3.0.7->colabcode)\n",
            "  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl.metadata (755 bytes)\n",
            "Collecting notebook-shim>=0.2.3 (from nbclassic~=0.2->jupyterlab==3.0.7->colabcode)\n",
            "  Downloading notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
            "INFO: pip is looking at multiple versions of nbclassic to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting nbclassic~=0.2 (from jupyterlab==3.0.7->colabcode)\n",
            "  Downloading nbclassic-0.5.5-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Downloading nbclassic-0.5.4-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Downloading nbclassic-0.5.3-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Downloading nbclassic-0.5.2-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Downloading nbclassic-0.5.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "  Downloading nbclassic-0.4.8-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading nbclassic-0.4.7-py3-none-any.whl.metadata (2.6 kB)\n",
            "INFO: pip is still looking at multiple versions of nbclassic to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading nbclassic-0.4.6-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading nbclassic-0.4.5-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading nbclassic-0.4.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading nbclassic-0.4.3-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading nbclassic-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading nbclassic-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading nbclassic-0.3.7-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting notebook<7 (from nbclassic~=0.2->jupyterlab==3.0.7->colabcode)\n",
            "  Downloading notebook-6.5.7-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: decorator in ./venv_wav2lip/lib/python3.11/site-packages (from ipython->jupyterlab==3.0.7->colabcode) (5.2.1)\n",
            "Requirement already satisfied: ipython-pygments-lexers in ./venv_wav2lip/lib/python3.11/site-packages (from ipython->jupyterlab==3.0.7->colabcode) (1.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in ./venv_wav2lip/lib/python3.11/site-packages (from ipython->jupyterlab==3.0.7->colabcode) (0.19.2)\n",
            "Requirement already satisfied: matplotlib-inline in ./venv_wav2lip/lib/python3.11/site-packages (from ipython->jupyterlab==3.0.7->colabcode) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in ./venv_wav2lip/lib/python3.11/site-packages (from ipython->jupyterlab==3.0.7->colabcode) (4.9.0)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./venv_wav2lip/lib/python3.11/site-packages (from ipython->jupyterlab==3.0.7->colabcode) (3.0.51)\n",
            "Requirement already satisfied: pygments>=2.4.0 in ./venv_wav2lip/lib/python3.11/site-packages (from ipython->jupyterlab==3.0.7->colabcode) (2.19.2)\n",
            "Requirement already satisfied: stack_data in ./venv_wav2lip/lib/python3.11/site-packages (from ipython->jupyterlab==3.0.7->colabcode) (0.6.3)\n",
            "Requirement already satisfied: typing_extensions>=4.6 in ./venv_wav2lip/lib/python3.11/site-packages (from ipython->jupyterlab==3.0.7->colabcode) (4.14.1)\n",
            "Requirement already satisfied: idna>=2.8 in ./venv_wav2lip/lib/python3.11/site-packages (from anyio<4,>=3.1.0->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (3.10)\n",
            "Collecting sniffio>=1.1 (from anyio<4,>=3.1.0->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode)\n",
            "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./venv_wav2lip/lib/python3.11/site-packages (from jedi>=0.16->ipython->jupyterlab==3.0.7->colabcode) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in ./venv_wav2lip/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (25.3.0)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.18.0->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode)\n",
            "  Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema>=4.18.0->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode)\n",
            "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema>=4.18.0->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode)\n",
            "  Downloading rpds_py-0.26.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv_wav2lip/lib/python3.11/site-packages (from jupyter-client>=6.1.12->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (2.9.0.post0)\n",
            "Collecting beautifulsoup4 (from nbconvert>=6.4.4->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode)\n",
            "  Using cached beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting bleach!=5.0.0 (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode)\n",
            "  Downloading bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting defusedxml (from nbconvert>=6.4.4->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode)\n",
            "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
            "Collecting jupyterlab-pygments (from nbconvert>=6.4.4->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode)\n",
            "  Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting mistune<4,>=2.0.3 (from nbconvert>=6.4.4->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode)\n",
            "  Downloading mistune-3.1.3-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting nbclient>=0.5.0 (from nbconvert>=6.4.4->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode)\n",
            "  Downloading nbclient-0.10.2-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting pandocfilters>=1.4.1 (from nbconvert>=6.4.4->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode)\n",
            "  Downloading pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting fastjsonschema>=2.15 (from nbformat>=5.2.0->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode)\n",
            "  Downloading fastjsonschema-2.21.1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting jupyter-client>=6.1.12 (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode)\n",
            "  Downloading jupyter_client-7.4.9-py3-none-any.whl.metadata (8.5 kB)\n",
            "INFO: pip is looking at multiple versions of notebook to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting notebook<7 (from nbclassic~=0.2->jupyterlab==3.0.7->colabcode)\n",
            "  Downloading notebook-6.5.6-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting pyzmq>=17 (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode)\n",
            "  Downloading pyzmq-24.0.1-cp311-cp311-macosx_10_15_universal2.whl.metadata (4.8 kB)\n",
            "Collecting notebook<7 (from nbclassic~=0.2->jupyterlab==3.0.7->colabcode)\n",
            "  Downloading notebook-6.5.5-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading notebook-6.5.4-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading notebook-6.5.3-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading notebook-6.5.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading notebook-6.5.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading notebook-6.4.13-py3-none-any.whl.metadata (2.5 kB)\n",
            "INFO: pip is still looking at multiple versions of notebook to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading notebook-6.4.12-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading notebook-6.4.11-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading notebook-6.4.10-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading notebook-6.4.9-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading notebook-6.4.8-py3-none-any.whl.metadata (2.4 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading notebook-6.4.7-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading notebook-6.4.6-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading notebook-6.4.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: ipykernel in ./venv_wav2lip/lib/python3.11/site-packages (from notebook<7->nbclassic~=0.2->jupyterlab==3.0.7->colabcode) (6.30.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in ./venv_wav2lip/lib/python3.11/site-packages (from pexpect>4.3->ipython->jupyterlab==3.0.7->colabcode) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in ./venv_wav2lip/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython->jupyterlab==3.0.7->colabcode) (0.2.13)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv_wav2lip/lib/python3.11/site-packages (from requests>=2.31->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv_wav2lip/lib/python3.11/site-packages (from requests>=2.31->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./venv_wav2lip/lib/python3.11/site-packages (from requests>=2.31->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2025.7.14)\n",
            "Collecting argon2-cffi-bindings (from argon2-cffi->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode)\n",
            "  Downloading argon2_cffi_bindings-25.1.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: executing>=1.2.0 in ./venv_wav2lip/lib/python3.11/site-packages (from stack_data->ipython->jupyterlab==3.0.7->colabcode) (2.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in ./venv_wav2lip/lib/python3.11/site-packages (from stack_data->ipython->jupyterlab==3.0.7->colabcode) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in ./venv_wav2lip/lib/python3.11/site-packages (from stack_data->ipython->jupyterlab==3.0.7->colabcode) (0.2.3)\n",
            "Collecting webencodings (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode)\n",
            "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting tinycss2<1.5,>=1.1.0 (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode)\n",
            "  Using cached tinycss2-1.4.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: six>=1.5 in ./venv_wav2lip/lib/python3.11/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.17.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in ./venv_wav2lip/lib/python3.11/site-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.17.1)\n",
            "Collecting soupsieve>1.2 (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode)\n",
            "  Using cached soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: appnope>=0.1.2 in ./venv_wav2lip/lib/python3.11/site-packages (from ipykernel->notebook<7->nbclassic~=0.2->jupyterlab==3.0.7->colabcode) (0.1.4)\n",
            "Requirement already satisfied: comm>=0.1.1 in ./venv_wav2lip/lib/python3.11/site-packages (from ipykernel->notebook<7->nbclassic~=0.2->jupyterlab==3.0.7->colabcode) (0.2.3)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in ./venv_wav2lip/lib/python3.11/site-packages (from ipykernel->notebook<7->nbclassic~=0.2->jupyterlab==3.0.7->colabcode) (1.8.15)\n",
            "Requirement already satisfied: psutil>=5.7 in ./venv_wav2lip/lib/python3.11/site-packages (from ipykernel->notebook<7->nbclassic~=0.2->jupyterlab==3.0.7->colabcode) (7.0.0)\n",
            "Requirement already satisfied: pycparser in ./venv_wav2lip/lib/python3.11/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (2.22)\n",
            "Downloading colabcode-0.3.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading jupyterlab-3.0.7-py3-none-any.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
            "\u001b[?25hDownloading nest_asyncio-1.4.3-py3-none-any.whl (5.3 kB)\n",
            "Downloading uvicorn-0.13.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.8/82.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pyngrok-7.3.0-py3-none-any.whl (25 kB)\n",
            "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Downloading jupyter_server-1.24.0-py3-none-any.whl (347 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.5/347.5 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nbclassic-0.3.7-py3-none-any.whl (13 kB)\n",
            "Using cached PyYAML-6.0.2-cp311-cp311-macosx_11_0_arm64.whl (172 kB)\n",
            "Downloading anyio-3.7.1-py3-none-any.whl (80 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading babel-2.17.0-py3-none-any.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.12.0-py3-none-any.whl (36 kB)\n",
            "Downloading jsonschema-4.25.0-py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nbconvert-7.16.6-py3-none-any.whl (258 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.5/258.5 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading notebook-6.4.5-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25hDownloading notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
            "Downloading Send2Trash-1.8.3-py3-none-any.whl (18 kB)\n",
            "Downloading terminado-0.18.1-py3-none-any.whl (14 kB)\n",
            "Downloading argon2_cffi-25.1.0-py3-none-any.whl (14 kB)\n",
            "Downloading prometheus_client-0.22.1-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.7/58.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bleach-6.2.0-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.4/163.4 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastjsonschema-2.21.1-py3-none-any.whl (23 kB)\n",
            "Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
            "Downloading mistune-3.1.3-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nbclient-0.10.2-py3-none-any.whl (25 kB)\n",
            "Downloading pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
            "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
            "Downloading rpds_py-0.26.0-cp311-cp311-macosx_11_0_arm64.whl (358 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.0/358.0 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Downloading argon2_cffi_bindings-25.1.0-cp39-abi3-macosx_11_0_arm64.whl (31 kB)\n",
            "Using cached beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
            "Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
            "Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
            "Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
            "Using cached soupsieve-2.7-py3-none-any.whl (36 kB)\n",
            "Using cached tinycss2-1.4.0-py3-none-any.whl (26 kB)\n",
            "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: webencodings, ipython-genutils, fastjsonschema, websocket-client, tinycss2, terminado, soupsieve, sniffio, Send2Trash, rpds-py, PyYAML, prometheus-client, pandocfilters, nest-asyncio, mistune, jupyterlab-pygments, json5, h11, defusedxml, click, bleach, babel, uvicorn, referencing, pyngrok, beautifulsoup4, argon2-cffi-bindings, anyio, jsonschema-specifications, argon2-cffi, jsonschema, nbformat, nbclient, nbconvert, notebook, jupyter-server, notebook-shim, jupyterlab-server, nbclassic, jupyterlab, colabcode\n",
            "  Attempting uninstall: nest-asyncio\n",
            "    Found existing installation: nest-asyncio 1.6.0\n",
            "    Uninstalling nest-asyncio-1.6.0:\n",
            "      Successfully uninstalled nest-asyncio-1.6.0\n",
            "Successfully installed PyYAML-6.0.2 Send2Trash-1.8.3 anyio-3.7.1 argon2-cffi-25.1.0 argon2-cffi-bindings-25.1.0 babel-2.17.0 beautifulsoup4-4.13.4 bleach-6.2.0 click-7.1.2 colabcode-0.3.0 defusedxml-0.7.1 fastjsonschema-2.21.1 h11-0.16.0 ipython-genutils-0.2.0 json5-0.12.0 jsonschema-4.25.0 jsonschema-specifications-2025.4.1 jupyter-server-1.24.0 jupyterlab-3.0.7 jupyterlab-pygments-0.3.0 jupyterlab-server-2.27.3 mistune-3.1.3 nbclassic-0.3.7 nbclient-0.10.2 nbconvert-7.16.6 nbformat-5.10.4 nest-asyncio-1.4.3 notebook-6.4.5 notebook-shim-0.2.4 pandocfilters-1.5.1 prometheus-client-0.22.1 pyngrok-7.3.0 referencing-0.36.2 rpds-py-0.26.0 sniffio-1.3.1 soupsieve-2.7 terminado-0.18.1 tinycss2-1.4.0 uvicorn-0.13.1 webencodings-0.5.1 websocket-client-1.8.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'wget'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m get_ipython().run_line_magic(\u001b[33m'\u001b[39m\u001b[33mpip\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33minstall colabcode\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcolabcode\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ColabCode\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mColabCode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mport\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/PROJECTX/nexcaster-news.v1/venv_wav2lip/lib/python3.11/site-packages/colabcode/code.py:42\u001b[39m, in \u001b[36mColabCode.__init__\u001b[39m\u001b[34m(self, port, password, authtoken, mount_drive, code, lab)\u001b[39m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28mself\u001b[39m._run_lab()\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._code:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_install_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m     \u001b[38;5;28mself\u001b[39m._install_extensions()\n\u001b[32m     44\u001b[39m     \u001b[38;5;28mself\u001b[39m._start_server()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/PROJECTX/nexcaster-news.v1/venv_wav2lip/lib/python3.11/site-packages/colabcode/code.py:49\u001b[39m, in \u001b[36mColabCode._install_code\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_install_code\u001b[39m():\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttps://code-server.dev/install.sh\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPIPE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m     subprocess.run(\n\u001b[32m     51\u001b[39m         [\u001b[33m\"\u001b[39m\u001b[33msh\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33minstall.sh\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m--version\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCODESERVER_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m],\n\u001b[32m     52\u001b[39m         stdout=subprocess.PIPE,\n\u001b[32m     53\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.8/lib/python3.11/subprocess.py:548\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    545\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mstdout\u001b[39m\u001b[33m'\u001b[39m] = PIPE\n\u001b[32m    546\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mstderr\u001b[39m\u001b[33m'\u001b[39m] = PIPE\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[32m    549\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    550\u001b[39m         stdout, stderr = process.communicate(\u001b[38;5;28minput\u001b[39m, timeout=timeout)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.8/lib/python3.11/subprocess.py:1026\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[39m\n\u001b[32m   1022\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.text_mode:\n\u001b[32m   1023\u001b[39m             \u001b[38;5;28mself\u001b[39m.stderr = io.TextIOWrapper(\u001b[38;5;28mself\u001b[39m.stderr,\n\u001b[32m   1024\u001b[39m                     encoding=encoding, errors=errors)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1036\u001b[39m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[32m   1037\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m.stdin, \u001b[38;5;28mself\u001b[39m.stdout, \u001b[38;5;28mself\u001b[39m.stderr)):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.8/lib/python3.11/subprocess.py:1953\u001b[39m, in \u001b[36mPopen._execute_child\u001b[39m\u001b[34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[39m\n\u001b[32m   1951\u001b[39m     err_msg = os.strerror(errno_num)\n\u001b[32m   1952\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m err_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1953\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[32m   1954\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1955\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg)\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'wget'"
          ]
        }
      ],
      "source": [
        "## 1. Setup Google Colab\n",
        "\n",
        "%pip install colabcode\n",
        "\n",
        "from colabcode import ColabCode\n",
        "ColabCode(port=10000)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "IuRy6i3fHcU6",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Setup Environment and Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nqnFp9OHcU6",
        "outputId": "ea6c5fe5-eb70-486d-8f87-6145a7b0c1c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA available: False\n",
            "Running on CPU - this will be slow!\n"
          ]
        }
      ],
      "source": [
        "# Check GPU availability\n",
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "else:\n",
        "    print(\"Running on CPU - this will be slow!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vku2r1A9HcU6",
        "outputId": "e777a64f-53a7-4f00-c1f2-4ead21d23ce7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing dependencies in order...\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDependencies installed!\n"
          ]
        }
      ],
      "source": [
        "# Alternative: Install in order to minimize conflicts\n",
        "print(\"Installing dependencies in order...\")\n",
        "\n",
        "# Install core packages first\n",
        "%pip install -q numpy==1.26.4\n",
        "%pip install -q scikit-learn==1.6.1\n",
        "\n",
        "# Install OpenCV packages\n",
        "%pip install -q opencv-python==4.8.1.78\n",
        "%pip install -q opencv-contrib-python==4.8.1.78\n",
        "\n",
        "# Install audio processing\n",
        "%pip install -q audioread==3.0.1\n",
        "%pip install -q librosa==0.11.0\n",
        "%pip install -q soundfile==0.13.1\n",
        "\n",
        "# Install utilities\n",
        "%pip install -q tqdm==4.67.1\n",
        "%pip install -q numba==0.61.2\n",
        "\n",
        "# Install face processing last\n",
        "%pip install -q face_alignment\n",
        "%pip install -q mediapipe\n",
        "\n",
        "print(\"Dependencies installed!\")"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "09K1tL1nHcU6",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Setup Wav2Lip Repository\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ex9eMmvXHcU7",
        "outputId": "528517d2-837d-406a-cf1b-966d126d88c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wav2Lip repository cloned!\n",
            "/content/Wav2Lip/Wav2Lip\n"
          ]
        }
      ],
      "source": [
        "# Clone the official Wav2Lip repository\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "if not os.path.exists('Wav2Lip'):\n",
        "    subprocess.run(['git', 'clone', 'https://github.com/Rudrabha/Wav2Lip.git'])\n",
        "    print(\"Wav2Lip repository cloned!\")\n",
        "else:\n",
        "    print(\"Wav2Lip repository already exists!\")\n",
        "\n",
        "# Change to Wav2Lip directory\n",
        "%cd Wav2Lip\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "gH5OPKNPHcU7",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. Download Wav2Lip Checkpoint (Fixed - Using Hugging Face)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRT-1MD0HcU7",
        "outputId": "84932ad7-8424-45b9-b166-a6fc180914e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading Wav2Lip checkpoint from Hugging Face...\n",
            "Source: https://huggingface.co/numz/wav2lip_studio/blob/main/Wav2lip/wav2lip.pth\n",
            "Downloading wav2lip.pth (436 MB)...\n",
            "✅ Checkpoint downloaded successfully!\n",
            "✅ Checkpoint file size: 415.6 MB\n",
            "✅ File size looks correct!\n"
          ]
        }
      ],
      "source": [
        "# Create checkpoints directory\n",
        "os.makedirs(\"checkpoints\", exist_ok=True)\n",
        "\n",
        "# Download wav2lip checkpoint if not exists\n",
        "checkpoint_path = \"checkpoints/wav2lip.pth\"\n",
        "if not os.path.exists(checkpoint_path):\n",
        "    print(\"Downloading Wav2Lip checkpoint from Hugging Face...\")\n",
        "    print(\"Source: https://huggingface.co/numz/wav2lip_studio/blob/main/Wav2lip/wav2lip.pth\")\n",
        "\n",
        "    # Use the working Hugging Face download link\n",
        "    import urllib.request\n",
        "    import shutil\n",
        "\n",
        "    print(\"Downloading wav2lip.pth (436 MB)...\")\n",
        "    hf_url = \"https://huggingface.co/numz/wav2lip_studio/resolve/main/Wav2lip/wav2lip.pth?download=true\"\n",
        "\n",
        "    try:\n",
        "        # Download with progress indication\n",
        "        with urllib.request.urlopen(hf_url) as response:\n",
        "            with open(checkpoint_path, 'wb') as f:\n",
        "                shutil.copyfileobj(response, f)\n",
        "        print(\"✅ Checkpoint downloaded successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Download failed: {e}\")\n",
        "        print(\"Trying alternative method with wget...\")\n",
        "        try:\n",
        "            subprocess.run([\n",
        "                \"wget\", \"-O\", checkpoint_path,\n",
        "                \"https://huggingface.co/numz/wav2lip_studio/resolve/main/Wav2lip/wav2lip.pth\"\n",
        "            ], check=True)\n",
        "            print(\"✅ Checkpoint downloaded with wget!\")\n",
        "        except Exception as e2:\n",
        "            print(f\"❌ Both download methods failed: {e2}\")\n",
        "            print(\"Please manually download from: https://huggingface.co/numz/wav2lip_studio/resolve/main/Wav2lip/wav2lip.pth\")\n",
        "else:\n",
        "    print(\"Checkpoint already exists!\")\n",
        "\n",
        "# Verify checkpoint file\n",
        "if os.path.exists(checkpoint_path):\n",
        "    checkpoint_size = os.path.getsize(checkpoint_path) / (1024*1024)\n",
        "    print(f\"✅ Checkpoint file size: {checkpoint_size:.1f} MB\")\n",
        "    if checkpoint_size > 400:  # Expected size is 436 MB\n",
        "        print(\"✅ File size looks correct!\")\n",
        "    else:\n",
        "        print(\"⚠️ File size seems small, download may be incomplete\")\n",
        "else:\n",
        "    print(\"❌ ERROR: Checkpoint file not found!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "ahZ4WyPEHcU7",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. Upload Input Files\n",
        "\n",
        "You need to upload:\n",
        "1. **Face video**: `test_video_newscaster.mp4`\n",
        "2. **Audio file**: `headline_opening_1.mp3`\n",
        "\n",
        "Run the cell below and upload your files when prompted.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "jo-ZWbP3HcU7",
        "outputId": "d62c8779-22c9-4ac1-af45-ea553cc34c23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Upload your video and audio files:\n",
            "1. Face video (test_video_newscaster.mp4)\n",
            "2. Audio file (headline_opening_1.mp3)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3aa1095e-84b2-430d-8ee9-495037535cf4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3aa1095e-84b2-430d-8ee9-495037535cf4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving test_video_newscaster.mp4 to test_video_newscaster (1).mp4\n",
            "Saving test_audio_newscaster.mp3 to test_audio_newscaster.mp3\n",
            "Video file moved to: test_video_newscaster.mp4\n",
            "Audio file moved to: generated/audio/headline_opening_1.mp3\n",
            "\n",
            "File upload complete!\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "# Create directories for uploads\n",
        "os.makedirs(\"uploads\", exist_ok=True)\n",
        "os.makedirs(\"generated/audio\", exist_ok=True)\n",
        "\n",
        "print(\"Upload your video and audio files:\")\n",
        "print(\"1. Face video (test_video_newscaster.mp4)\")\n",
        "print(\"2. Audio file (headline_opening_1.mp3)\")\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Move uploaded files to appropriate locations\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith('.mp4'):\n",
        "        shutil.move(filename, 'test_video_newscaster.mp4')\n",
        "        print(f\"Video file moved to: test_video_newscaster.mp4\")\n",
        "    elif filename.endswith('.mp3'):\n",
        "        shutil.move(filename, 'generated/audio/headline_opening_1.mp3')\n",
        "        print(f\"Audio file moved to: generated/audio/headline_opening_1.mp3\")\n",
        "    else:\n",
        "        print(f\"Unknown file type: {filename}\")\n",
        "\n",
        "print(\"\\nFile upload complete!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "UW_96mfoHcU7",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. Run Wav2Lip Inference\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dewy3DV_X9GK",
        "outputId": "816a8bf0-08c5-4b2c-c400-067696ff0690"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current directory: /content/Wav2Lip/Wav2Lip\n",
            "\n",
            "Files in current directory:\n",
            "['hq_wav2lip_train.py', '__pycache__', 'README.md', 'preprocess.py', '.git', 'evaluation', 'hparams.py', 'temp', 'models', 'color_syncnet_train.py', 'results', 'wav2lip_train.py', 'filelists', 'face_detection', '.gitignore', 'inference.py', 'requirements.txt', 'checkpoints', 'audio.py']\n",
            "\n",
            "Checking for files in different possible locations:\n",
            "  checkpoints/wav2lip.pth: ❌\n",
            "  ../checkpoints/wav2lip.pth: ✅\n",
            "  Wav2Lip/checkpoints/wav2lip.pth: ❌\n",
            "  test_video_newscaster.mp4: ❌\n",
            "  ../test_video_newscaster.mp4: ✅\n",
            "  generated/audio/headline_opening_1.mp3: ❌\n",
            "  ../generated/audio/headline_opening_1.mp3: ✅\n"
          ]
        }
      ],
      "source": [
        "# Check current directory and file structure\n",
        "import os\n",
        "print(f\"Current directory: {os.getcwd()}\")\n",
        "print(\"\\nFiles in current directory:\")\n",
        "print(os.listdir('.'))\n",
        "\n",
        "print(\"\\nChecking for files in different possible locations:\")\n",
        "possible_paths = [\n",
        "    'checkpoints/wav2lip.pth',\n",
        "    '../checkpoints/wav2lip.pth',\n",
        "    'Wav2Lip/checkpoints/wav2lip.pth',\n",
        "    'test_video_newscaster.mp4',\n",
        "    '../test_video_newscaster.mp4',\n",
        "    'generated/audio/headline_opening_1.mp3',\n",
        "    '../generated/audio/headline_opening_1.mp3'\n",
        "]\n",
        "\n",
        "for path in possible_paths:\n",
        "    exists = os.path.exists(path)\n",
        "    print(f\"  {path}: {'✅' if exists else '❌'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbEjffUsHcU7",
        "outputId": "0a7e13b1-f266-4dda-b58f-aaab2301d379"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Changed to directory: /content/Wav2Lip\n",
            "\n",
            "Checking files in current directory:\n",
            "  checkpoints/wav2lip.pth: ✅\n",
            "  test_video_newscaster.mp4: ✅\n",
            "  generated/audio/headline_opening_1.mp3: ✅\n",
            "\n",
            "Running Wav2Lip inference with corrected paths...\n",
            "Parameters:\n",
            "- wav2lip_batch_size: 4\n",
            "- resize_factor: 2\n",
            "- chunk_size: 25\n",
            "Command: python Wav2Lip/inference.py --checkpoint_path checkpoints/wav2lip.pth --face test_video_newscaster.mp4 --audio generated/audio/headline_opening_1.mp3 --outfile results/output_colab_test.mp4 --wav2lip_batch_size 4 --resize_factor 2\n",
            "❌ Inference failed with error: Command '['python', 'Wav2Lip/inference.py', '--checkpoint_path', 'checkpoints/wav2lip.pth', '--face', 'test_video_newscaster.mp4', '--audio', 'generated/audio/headline_opening_1.mp3', '--outfile', 'results/output_colab_test.mp4', '--wav2lip_batch_size', '4', '--resize_factor', '2']' returned non-zero exit status 1.\n",
            "STDOUT: Using cpu for inference.\n",
            "Reading video frames...\n",
            "Number of frames available for inference: 2568\n",
            "Extracting raw audio...\n",
            "\n",
            "STDERR: ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "[mp3 @ 0x55df7d37e140] Estimating duration from bitrate, this may be inaccurate\n",
            "Input #0, mp3, from 'generated/audio/headline_opening_1.mp3':\n",
            "  Metadata:\n",
            "    encoder         : Lavf59.27.100\n",
            "  Duration: 00:00:16.56, start: 0.000000, bitrate: 128 kb/s\n",
            "  Stream #0:0: Audio: mp3, 44100 Hz, mono, fltp, 128 kb/s\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, wav, to 'temp/temp.wav':\n",
            "  Metadata:\n",
            "    ISFT            : Lavf58.76.100\n",
            "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, mono, s16, 705 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 pcm_s16le\n",
            "size=       2kB time=00:00:00.00 bitrate=N/A speed=N/A    \n",
            "size=    1427kB time=00:00:16.53 bitrate= 706.8kbits/s speed= 266x    \n",
            "video:0kB audio:1426kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.005340%\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Wav2Lip/Wav2Lip/inference.py\", line 280, in <module>\n",
            "    main()\n",
            "  File \"/content/Wav2Lip/Wav2Lip/inference.py\", line 225, in main\n",
            "    mel = audio.melspectrogram(wav)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Wav2Lip/Wav2Lip/audio.py\", line 47, in melspectrogram\n",
            "    S = _amp_to_db(_linear_to_mel(np.abs(D))) - hp.ref_level_db\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Wav2Lip/Wav2Lip/audio.py\", line 95, in _linear_to_mel\n",
            "    _mel_basis = _build_mel_basis()\n",
            "                 ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Wav2Lip/Wav2Lip/audio.py\", line 100, in _build_mel_basis\n",
            "    return librosa.filters.mel(hp.sample_rate, hp.n_fft, n_mels=hp.num_mels,\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "TypeError: mel() takes 0 positional arguments but 2 positional arguments (and 3 keyword-only arguments) were given\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Navigate to the correct directory (one level up)\n",
        "import os\n",
        "os.chdir('..')\n",
        "print(f\"Changed to directory: {os.getcwd()}\")\n",
        "\n",
        "# Verify files are now accessible\n",
        "print(\"\\nChecking files in current directory:\")\n",
        "files_to_check = [\n",
        "    'checkpoints/wav2lip.pth',\n",
        "    'test_video_newscaster.mp4',\n",
        "    'generated/audio/headline_opening_1.mp3'\n",
        "]\n",
        "\n",
        "for file_path in files_to_check:\n",
        "    exists = os.path.exists(file_path)\n",
        "    print(f\"  {file_path}: {'✅' if exists else '❌'}\")\n",
        "\n",
        "# Create results directory\n",
        "os.makedirs(\"results\", exist_ok=True)\n",
        "\n",
        "print(\"\\nRunning Wav2Lip inference with corrected paths...\")\n",
        "print(\"Parameters:\")\n",
        "print(\"- wav2lip_batch_size: 4\")\n",
        "print(\"- resize_factor: 2\")\n",
        "print(\"- chunk_size: 25\")\n",
        "\n",
        "# Run the inference command with correct paths\n",
        "command = [\n",
        "    \"python\", \"Wav2Lip/inference.py\",  # Note: inference.py is in Wav2Lip subdirectory\n",
        "    \"--checkpoint_path\", \"checkpoints/wav2lip.pth\",\n",
        "    \"--face\", \"test_video_newscaster.mp4\",\n",
        "    \"--audio\", \"generated/audio/headline_opening_1.mp3\",\n",
        "    \"--outfile\", \"results/output_colab_test.mp4\",\n",
        "    \"--wav2lip_batch_size\", \"4\",\n",
        "    \"--resize_factor\", \"2\"\n",
        "]\n",
        "\n",
        "print(f\"Command: {' '.join(command)}\")\n",
        "\n",
        "try:\n",
        "    result = subprocess.run(command, capture_output=True, text=True, check=True)\n",
        "    print(\"✅ Inference completed successfully!\")\n",
        "    print(\"STDOUT:\", result.stdout)\n",
        "    if result.stderr:\n",
        "        print(\"STDERR:\", result.stderr)\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"❌ Inference failed with error: {e}\")\n",
        "    print(\"STDOUT:\", e.stdout)\n",
        "    print(\"STDERR:\", e.stderr)\n",
        "except Exception as e:\n",
        "    print(f\"❌ Unexpected error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EB5btFMgYpL2",
        "outputId": "6d2b2df2-3015-4bd3-c3ba-df622995131b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fixing librosa compatibility issue...\n",
            "Found existing installation: librosa 0.11.0\n",
            "Uninstalling librosa-0.11.0:\n",
            "  Successfully uninstalled librosa-0.11.0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.8/203.8 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hlibrosa version fixed!\n",
            "\n",
            "Running Wav2Lip inference with fixed librosa...\n",
            "Command: python Wav2Lip/inference.py --checkpoint_path checkpoints/wav2lip.pth --face test_video_newscaster.mp4 --audio generated/audio/headline_opening_1.mp3 --outfile results/output_colab_test.mp4 --wav2lip_batch_size 4 --resize_factor 2\n",
            "❌ Inference failed with error: Command '['python', 'Wav2Lip/inference.py', '--checkpoint_path', 'checkpoints/wav2lip.pth', '--face', 'test_video_newscaster.mp4', '--audio', 'generated/audio/headline_opening_1.mp3', '--outfile', 'results/output_colab_test.mp4', '--wav2lip_batch_size', '4', '--resize_factor', '2']' returned non-zero exit status 1.\n",
            "STDOUT: \n",
            "STDERR: Traceback (most recent call last):\n",
            "  File \"/content/Wav2Lip/Wav2Lip/inference.py\", line 3, in <module>\n",
            "    import scipy, cv2, os, sys, argparse, audio\n",
            "  File \"/content/Wav2Lip/Wav2Lip/audio.py\", line 1, in <module>\n",
            "    import librosa\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/librosa/__init__.py\", line 211, in <module>\n",
            "    from . import core\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/librosa/core/__init__.py\", line 9, in <module>\n",
            "    from .constantq import *  # pylint: disable=wildcard-import\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/librosa/core/constantq.py\", line 1059, in <module>\n",
            "    dtype=np.complex,\n",
            "          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/numpy/__init__.py\", line 324, in __getattr__\n",
            "    raise AttributeError(__former_attrs__[attr])\n",
            "AttributeError: module 'numpy' has no attribute 'complex'.\n",
            "`np.complex` was a deprecated alias for the builtin `complex`. To avoid this error in existing code, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\n",
            "The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n",
            "    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'complex_'?\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Fix librosa compatibility issue\n",
        "print(\"Fixing librosa compatibility issue...\")\n",
        "\n",
        "# Uninstall current librosa\n",
        "%pip uninstall -y librosa\n",
        "\n",
        "# Install the specific version that works with Wav2Lip\n",
        "%pip install -q librosa==0.8.1\n",
        "\n",
        "print(\"librosa version fixed!\")\n",
        "\n",
        "# Now try the inference again\n",
        "print(\"\\nRunning Wav2Lip inference with fixed librosa...\")\n",
        "\n",
        "# Run the inference command with correct paths\n",
        "command = [\n",
        "    \"python\", \"Wav2Lip/inference.py\",\n",
        "    \"--checkpoint_path\", \"checkpoints/wav2lip.pth\",\n",
        "    \"--face\", \"test_video_newscaster.mp4\",\n",
        "    \"--audio\", \"generated/audio/headline_opening_1.mp3\",\n",
        "    \"--outfile\", \"results/output_colab_test.mp4\",\n",
        "    \"--wav2lip_batch_size\", \"4\",\n",
        "    \"--resize_factor\", \"2\"\n",
        "]\n",
        "\n",
        "print(f\"Command: {' '.join(command)}\")\n",
        "\n",
        "try:\n",
        "    result = subprocess.run(command, capture_output=True, text=True, check=True)\n",
        "    print(\"✅ Inference completed successfully!\")\n",
        "    print(\"STDOUT:\", result.stdout)\n",
        "    if result.stderr:\n",
        "        print(\"STDERR:\", result.stderr)\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"❌ Inference failed with error: {e}\")\n",
        "    print(\"STDOUT:\", e.stdout)\n",
        "    print(\"STDERR:\", e.stderr)\n",
        "except Exception as e:\n",
        "    print(f\"❌ Unexpected error: {e}\")"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "x07zFymwHcU8",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. Check Results and Download\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfDMPM0OHcU8"
      },
      "outputs": [],
      "source": [
        "# List output files\n",
        "print(\"Output files:\")\n",
        "if os.path.exists(\"results\"):\n",
        "    for file in os.listdir(\"results\"):\n",
        "        print(f\"  {file}\")\n",
        "\n",
        "# Check if output files exist and get their info\n",
        "output_files = [\n",
        "    \"results/output_colab_test.mp4\",\n",
        "    \"result_voice.mp4\"  # Default output name\n",
        "]\n",
        "\n",
        "import cv2\n",
        "\n",
        "for output_file in output_files:\n",
        "    if os.path.exists(output_file):\n",
        "        file_size = os.path.getsize(output_file) / (1024*1024)\n",
        "        print(f\"\\n✅ Output found: {output_file}\")\n",
        "        print(f\"   Size: {file_size:.1f} MB\")\n",
        "\n",
        "        # Get video info\n",
        "        try:\n",
        "            cap = cv2.VideoCapture(output_file)\n",
        "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "            duration = frame_count / fps if fps > 0 else 0\n",
        "            cap.release()\n",
        "\n",
        "            print(f\"   Resolution: {width}x{height}\")\n",
        "            print(f\"   FPS: {fps}\")\n",
        "            print(f\"   Duration: {duration:.2f} seconds\")\n",
        "            print(f\"   Frame count: {frame_count}\")\n",
        "        except Exception as e:\n",
        "            print(f\"   Error reading video info: {e}\")\n",
        "    else:\n",
        "        print(f\"❌ Output not found: {output_file}\")\n",
        "\n",
        "# Download the output file if it exists\n",
        "download_files = [f for f in output_files if os.path.exists(f)]\n",
        "\n",
        "if download_files:\n",
        "    print(f\"\\nDownloading {len(download_files)} output file(s)...\")\n",
        "    for file_path in download_files:\n",
        "        print(f\"Downloading: {file_path}\")\n",
        "        files.download(file_path)\n",
        "        print(f\"✅ Downloaded: {file_path}\")\n",
        "\n",
        "    print(\"\\n🎉 Wav2Lip inference test complete!\")\n",
        "    print(\"✨ Check the downloaded videos for results.\")\n",
        "else:\n",
        "    print(\"\\n❌ No output files found to download!\")\n",
        "    print(\"Please check the inference output above for errors.\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "3A-ePTOjHcU8",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 7. Advanced: Test with Chunked Parameters\n",
        "\n",
        "If you want to test with the exact chunked parameters from your original command:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0a82ee5SHcU8"
      },
      "outputs": [],
      "source": [
        "# Alternative: Test with enhanced chunked inference (if available)\n",
        "print(\"Testing with chunked parameters...\")\n",
        "print(\"This requires a custom inference script with chunking support.\")\n",
        "\n",
        "# Check if chunked inference script exists\n",
        "chunked_scripts = [\n",
        "    \"inference_chunked.py\",\n",
        "    \"../wav2lip_test/Wav2Lip/inference_chunked.py\"\n",
        "]\n",
        "\n",
        "chunked_script = None\n",
        "for script in chunked_scripts:\n",
        "    if os.path.exists(script):\n",
        "        chunked_script = script\n",
        "        break\n",
        "\n",
        "if chunked_script:\n",
        "    print(f\"Found chunked script: {chunked_script}\")\n",
        "\n",
        "    # Run with chunked parameters\n",
        "    chunked_command = [\n",
        "        \"python\", chunked_script,\n",
        "        \"--checkpoint_path\", \"checkpoints/wav2lip.pth\",\n",
        "        \"--face\", \"test_video_newscaster.mp4\",\n",
        "        \"--audio\", \"generated/audio/headline_opening_1.mp3\",\n",
        "        \"--outfile\", \"results/output_chunked_test.mp4\",\n",
        "        \"--wav2lip_batch_size\", \"4\",\n",
        "        \"--resize_factor\", \"2\",\n",
        "        \"--chunk_size\", \"25\"\n",
        "    ]\n",
        "\n",
        "    print(f\"Chunked command: {' '.join(chunked_command)}\")\n",
        "\n",
        "    try:\n",
        "        result = subprocess.run(chunked_command, capture_output=True, text=True, check=True)\n",
        "        print(\"✅ Chunked inference completed successfully!\")\n",
        "        print(\"STDOUT:\", result.stdout)\n",
        "        if result.stderr:\n",
        "            print(\"STDERR:\", result.stderr)\n",
        "\n",
        "        # Download chunked result if it exists\n",
        "        if os.path.exists(\"results/output_chunked_test.mp4\"):\n",
        "            files.download(\"results/output_chunked_test.mp4\")\n",
        "            print(\"✅ Downloaded chunked result!\")\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"❌ Chunked inference failed: {e}\")\n",
        "        print(\"STDOUT:\", e.stdout)\n",
        "        print(\"STDERR:\", e.stderr)\n",
        "else:\n",
        "    print(\"❌ No chunked inference script found.\")\n",
        "    print(\"Using standard inference.py instead.\")\n",
        "    print(\"For chunked processing, you would need to:\")\n",
        "    print(\"1. Upload your custom inference_chunked.py script\")\n",
        "    print(\"2. Or modify the existing inference.py to support chunking\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "C-NGfeTBHcU8",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 8. Performance Summary\n",
        "\n",
        "### Test Results:\n",
        "- **Device**: GPU (if available) or CPU\n",
        "- **Checkpoint Source**: [Hugging Face wav2lip_studio](https://huggingface.co/numz/wav2lip_studio/blob/main/Wav2lip/wav2lip.pth)\n",
        "- **Parameters tested**:\n",
        "  - `wav2lip_batch_size`: 4\n",
        "  - `resize_factor`: 2\n",
        "  - `chunk_size`: 25\n",
        "\n",
        "### Expected Output:\n",
        "- Lip-synced video with the provided audio\n",
        "- Resolution depends on resize_factor (2 = half resolution)\n",
        "- Quality optimized for the given parameters\n",
        "\n",
        "### Troubleshooting:\n",
        "- **Out of memory**: Reduce `wav2lip_batch_size` to 2 or 1\n",
        "- **Poor quality**: Try `resize_factor=1` for full resolution\n",
        "- **Slow processing**: Use GPU runtime in Colab (Runtime > Change runtime type > GPU)\n",
        "- **Download issues**: The Hugging Face checkpoint is working (436 MB)\n",
        "\n",
        "### Next Steps:\n",
        "1. Download and review the generated video\n",
        "2. Adjust parameters if needed and re-run\n",
        "3. Compare results with different parameter combinations\n",
        "\n",
        "**Fixed Issues:**\n",
        "- ✅ Updated to working Hugging Face checkpoint download\n",
        "- ✅ Removed broken Google Drive link\n",
        "- ✅ Fixed cell type formatting issues\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv_wav2lip",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
